{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.text_preprocessing import clean_text, transform_countvec, transform_tfidf\n",
    "import src.models.models as models\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"mathml_finalproj/data/train.csv\")\n",
    "test_raw = pd.read_csv(\"mathml_finalproj/data/test.csv\")\n",
    "y_test = pd.read_csv(\"mathml_finalproj/data/submit.csv\")\n",
    "\n",
    "train_clean = clean_text(train_raw)\n",
    "test_clean = clean_text(test_raw)\n",
    "y_train = train_clean[\"label\"]\n",
    "\n",
    "X_train, X_test, words = transform_tfidf(train_clean[\"text\"], test_clean[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "\n",
    "X_train, y_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = X_train.shape\n",
    "\n",
    "indices = np.random.permutation(n)\n",
    "X_train = X_train[indices,:]\n",
    "y_train = y_train[indices]\n",
    "folds = 5\n",
    "n_alphas = 10\n",
    "lambdas = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "\n",
    "avg_errors_by_penalty = np.empty((n_alphas + 1,len(lambdas)))\n",
    "\n",
    "for i, lambda_ in enumerate(lambdas):\n",
    "    errors = np.empty((n_alphas+ 1,folds))\n",
    "\n",
    "    for k in folds:\n",
    "        buckets = list(range(0, n + 1, n//folds))\n",
    "\n",
    "        val1 = buckets[k]\n",
    "        val2 = buckets[k+1]\n",
    "\n",
    "        x_dev = X_train[val1:val2,:]\n",
    "        x_train = np.delete(X_train, np.s_[val1:val2], axis=0)\n",
    "\n",
    "        y_dev = y_train[val1:val2,:]\n",
    "        y_train = np.delete(y_train, np.s_[val1:val2], axis=0)\n",
    "\n",
    "        errors[:,k] = models.gradient_descent(x_train, x_dev, y_train, y_dev,n_alphas, lambda_)\n",
    "\n",
    "    avg_errors_by_penalty[:,i] = np.mean(errors, axis=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
